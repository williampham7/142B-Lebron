model_lr_0.01_bs_128_dr_0.4:
  test_accuracies:
  - 0.7402597402597403
  - 0.7272727272727273
  - 0.7532467532467533
  - 0.6201298701298701
  - 0.8116883116883117
  - 0.8474025974025974
  - 0.8571428571428571
  - 0.7435064935064936
  - 0.8603896103896104
  - 0.8603896103896104
  - 0.8538961038961039
  - 0.8928571428571429
  - 0.8961038961038961
  - 0.8344155844155844
  - 0.8831168831168831
  - 0.8636363636363636
  - 0.9285714285714286
  - 0.8571428571428571
  - 0.9155844155844156
  - 0.9318181818181818
  - 0.9253246753246753
  - 0.9318181818181818
  - 0.8993506493506493
  - 0.9415584415584416
  - 0.9383116883116883
  train_accuracies:
  - 0.6747967479674797
  - 0.7333333333333333
  - 0.7715447154471544
  - 0.808130081300813
  - 0.8504065040650407
  - 0.8504065040650407
  - 0.8715447154471545
  - 0.8845528455284553
  - 0.8967479674796748
  - 0.8975609756097561
  - 0.8991869918699187
  - 0.9056910569105691
  - 0.926829268292683
  - 0.9211382113821138
  - 0.9040650406504065
  - 0.9252032520325203
  - 0.9552845528455285
  - 0.9536585365853658
  - 0.9512195121951219
  - 0.9560975609756097
  - 0.9642276422764228
  - 0.967479674796748
  - 0.9666666666666667
  - 0.9739837398373984
  - 0.975609756097561
  train_losses:
  - 2.808077123494652
  - 0.6374535780127456
  - 0.4567999707489479
  - 0.3841109465292799
  - 0.35380395592712777
  - 0.325169087377021
  - 0.3069214717644017
  - 0.2857851922027464
  - 0.2592877368616864
  - 0.246106427326435
  - 0.2405741437663877
  - 0.2335773956484911
  - 0.19775448456043151
  - 0.19997104183445133
  - 0.2134960574832389
  - 0.1772997124650614
  - 0.1442881485795587
  - 0.1237114867059196
  - 0.14103765303526467
  - 0.1340628415588441
  - 0.11010345846899157
  - 0.09033776962660192
  - 0.09585133984806092
  - 0.07679392187818279
  - 0.06160339502299704
