model_1:
  test_accuracies:
  - 0.7402597402597403
  - 0.8831168831168831
  - 0.9415584415584416
  - 0.8896103896103896
  - 0.922077922077922
  - 0.8441558441558441
  - 0.8798701298701299
  - 0.7987012987012987
  - 0.9512987012987013
  - 0.948051948051948
  - 0.935064935064935
  - 0.9285714285714286
  - 0.9512987012987013
  - 0.9448051948051948
  - 0.9512987012987013
  - 0.9253246753246753
  - 0.9318181818181818
  - 0.9383116883116883
  - 0.9512987012987013
  - 0.9448051948051948
  - 0.9545454545454546
  - 0.9577922077922078
  - 0.9512987012987013
  - 0.9545454545454546
  - 0.9512987012987013
  train_accuracies:
  - 0.7731707317073171
  - 0.8788617886178862
  - 0.9292682926829269
  - 0.9512195121951219
  - 0.9577235772357724
  - 0.9813008130081301
  - 0.9146341463414634
  - 0.973170731707317
  - 0.9845528455284552
  - 0.9926829268292683
  - 0.9975609756097561
  - 0.9943089430894309
  - 0.989430894308943
  - 0.9975609756097561
  - 0.9991869918699187
  - 0.9991869918699187
  - 0.9796747967479674
  - 0.9910569105691057
  - 1.0
  - 0.9991869918699187
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  train_losses:
  - 0.4491468093259548
  - 0.3020627656118657
  - 0.18008228065521736
  - 0.13099186705137655
  - 0.11224005234132453
  - 0.06456732808089838
  - 0.22300857874314958
  - 0.08200259765958398
  - 0.04331752511907399
  - 0.019076718936666726
  - 0.007343070797396945
  - 0.01555749252557445
  - 0.0366044928993636
  - 0.009159299432029342
  - 0.0026115634322639203
  - 0.002912691593466173
  - 0.05513790072873235
  - 0.026739755781685432
  - 0.006543071478287258
  - 0.0024274894134785102
  - 0.00040658787612205113
  - 0.00023232127399736545
  - 0.00011253819988550225
  - 7.84258649928677e-05
  - 7.591264827051344e-05
model_2:
  test_accuracies:
  - 0.7435064935064936
  - 0.7792207792207793
  - 0.814935064935065
  - 0.8571428571428571
  - 0.8798701298701299
  - 0.8668831168831169
  - 0.8928571428571429
  - 0.8701298701298701
  - 0.9058441558441559
  - 0.9090909090909091
  - 0.9188311688311688
  - 0.9318181818181818
  - 0.9058441558441559
  - 0.9188311688311688
  - 0.8798701298701299
  - 0.9155844155844156
  - 0.9188311688311688
  - 0.9188311688311688
  - 0.9123376623376623
  - 0.9155844155844156
  - 0.935064935064935
  - 0.9285714285714286
  - 0.9058441558441559
  - 0.9285714285714286
  - 0.9285714285714286
  train_accuracies:
  - 0.6731707317073171
  - 0.7601626016260162
  - 0.8097560975609757
  - 0.8552845528455284
  - 0.8674796747967479
  - 0.8959349593495934
  - 0.9089430894308943
  - 0.926829268292683
  - 0.9243902439024391
  - 0.9357723577235773
  - 0.9463414634146341
  - 0.959349593495935
  - 0.948780487804878
  - 0.9626016260162602
  - 0.9569105691056911
  - 0.948780487804878
  - 0.9544715447154472
  - 0.9577235772357724
  - 0.9723577235772358
  - 0.9813008130081301
  - 0.9845528455284552
  - 0.9845528455284552
  - 0.9910569105691057
  - 0.9796747967479674
  - 0.989430894308943
  train_losses:
  - 2.1871524690612545
  - 0.5398098980508199
  - 0.4113525907198588
  - 0.3532224027121939
  - 0.3282962361971537
  - 0.2629618312769789
  - 0.23123205267801517
  - 0.1959596644572126
  - 0.19255316964979094
  - 0.16569762519462322
  - 0.14827630272725734
  - 0.10992112862385385
  - 0.13586984846771247
  - 0.09993452085712091
  - 0.11127335787334336
  - 0.14691792043243967
  - 0.1258339183117316
  - 0.10734073210780214
  - 0.07164587096833601
  - 0.05134008340234679
  - 0.05243851108007072
  - 0.03566346136785427
  - 0.030547470014875497
  - 0.041937474567231126
  - 0.024081065272533796
model_3:
  test_accuracies:
  - 0.7402597402597403
  - 0.7564935064935064
  - 0.7467532467532467
  - 0.7532467532467533
  - 0.8993506493506493
  - 0.9253246753246753
  - 0.9285714285714286
  - 0.9577922077922078
  - 0.922077922077922
  - 0.961038961038961
  - 0.948051948051948
  - 0.9448051948051948
  - 0.9512987012987013
  - 0.9577922077922078
  - 0.9545454545454546
  - 0.9448051948051948
  - 0.9512987012987013
  - 0.9577922077922078
  - 0.948051948051948
  - 0.9545454545454546
  - 0.9545454545454546
  - 0.9512987012987013
  - 0.9577922077922078
  - 0.9577922077922078
  - 0.9545454545454546
  train_accuracies:
  - 0.7455284552845528
  - 0.8292682926829268
  - 0.8926829268292683
  - 0.9211382113821138
  - 0.9560975609756097
  - 0.9390243902439024
  - 0.9772357723577236
  - 0.983739837398374
  - 0.9796747967479674
  - 0.9861788617886179
  - 0.9869918699186991
  - 0.9910569105691057
  - 0.989430894308943
  - 0.9878048780487805
  - 0.9813008130081301
  - 0.9853658536585366
  - 0.9869918699186991
  - 0.9967479674796748
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  train_losses:
  - 0.5148368960958186
  - 0.35049132244373726
  - 0.24744505293485594
  - 0.19697374513721078
  - 0.1220033218766131
  - 0.14965904969873467
  - 0.06692145035973167
  - 0.042712709259211536
  - 0.05886579710172444
  - 0.038442700950815
  - 0.03455849568230834
  - 0.019428073716296897
  - 0.02661121464145135
  - 0.024737230499040305
  - 0.05284371634082096
  - 0.03694716702874114
  - 0.029494618497243743
  - 0.010253924535913015
  - 0.0015429306287132486
  - 0.00041716232487332735
  - 0.00027581548313985587
  - 0.0001948809564491671
  - 0.00010299930546626286
  - 5.6803866079381414e-05
  - 3.8914478571358615e-05
model_4:
  test_accuracies:
  - 0.7402597402597403
  - 0.7954545454545454
  - 0.8896103896103896
  - 0.8571428571428571
  - 0.9318181818181818
  - 0.9448051948051948
  - 0.948051948051948
  - 0.961038961038961
  - 0.9415584415584416
  - 0.9512987012987013
  - 0.9577922077922078
  - 0.9512987012987013
  - 0.935064935064935
  - 0.9285714285714286
  - 0.9577922077922078
  - 0.9545454545454546
  - 0.9545454545454546
  - 0.9577922077922078
  - 0.9577922077922078
  - 0.9545454545454546
  - 0.9577922077922078
  - 0.9675324675324676
  - 0.9577922077922078
  - 0.9577922077922078
  - 0.9577922077922078
  train_accuracies:
  - 0.767479674796748
  - 0.8634146341463415
  - 0.8878048780487805
  - 0.926829268292683
  - 0.948780487804878
  - 0.9658536585365853
  - 0.9699186991869919
  - 0.9829268292682927
  - 0.9715447154471545
  - 0.9869918699186991
  - 0.9926829268292683
  - 0.9959349593495935
  - 0.9983739837398374
  - 0.9878048780487805
  - 0.9975609756097561
  - 0.9975609756097561
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  train_losses:
  - 0.46583675223637405
  - 0.3049436558068283
  - 0.25444940490935875
  - 0.177297127901054
  - 0.13135153394404467
  - 0.1093913118135396
  - 0.08218806174288436
  - 0.04484913358843424
  - 0.07992814425530473
  - 0.0402176086586423
  - 0.02170400678916509
  - 0.015255423059793022
  - 0.009577991298543729
  - 0.028622737360315596
  - 0.010098622868413
  - 0.00661341287990714
  - 0.0026345580727301114
  - 0.0015068051180465343
  - 0.0010963004830149494
  - 0.000716840603665214
  - 0.000885302727728253
  - 0.0008438013863018184
  - 0.0005687377541714038
  - 0.0004885726993074413
  - 0.0004280374710350127
